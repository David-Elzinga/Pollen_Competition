{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27555730",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This notebook is designed to rank the parameter sets from the LHS using data genereated from single and double accession simulations from the pollen competition ABM. The ranking is performed as follows. \n",
    "\n",
    "1. Calculate the absolute difference between the mean pollen tube length from each single-accession model simulation with the mean estimated from the Kolba-Capaldi paper at 3, 6, 9, and 24 hours post-germination.\n",
    "2. Conduct a Kolmogorov-Smirnov (KS) test to determine if the pollen tube lengths from each single-accession model simulation differ from an exponential distribution (with mean from the Kolba-Capaldi paper) at 3, 6, 9, and 24 hours post-germination.\n",
    "3. Calculate the absolute difference between the proportion of seeds fertilized from each double-accession model simulation with the empirically known proportion of seeds fertilized. \n",
    "4. Rank the parameter sets according to the following methods. \n",
    "    * **Mean Rank**: Total sum (across all realizations) of the values generated from step 1. \n",
    "    * **Distribution Rank**: Total count (across all realizations) of hypothesis tests ran in step 2 that fail to reject the null hypothesis (that the distributions are the same) at the 0.05 significance level. \n",
    "    * **Fertilized Ovules Rank**: Total sum (across all realizations) of the values generated from step 3.\n",
    "5. Aggregate the ranks from step 4 for each parameter according to two methods. \n",
    "    * **Mean Length \\& Fertilized Ovules (MLFO)**: The sum of the parameter's Mean Rank and Fertilized Ovules Rank\n",
    "    * **Distribution \\& Fertilized Ovules (DFO)**: The sum of the parameter's Distribution Rank and Fertilized Ovules Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa58e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pickle\n",
    "import ast\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef787c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the model generated data for the single accession. \n",
    "cols = ['accession', 'count patches with [pcolor = yellow]','count patches with [pcolor = blue] / 6', 'count patches with [pcolor = red] / 6', \\\n",
    "     'r3L', 'r6L', 'r9L', 'r24L','LHS-paramcombo-counter', 'r3C', 'r6C', 'r9C', 'r24C']\n",
    "\n",
    "single_acc_df = pd.read_csv(os.getcwd() + '\\\\Experiment Data\\\\calibration_data_single_accession', usecols=cols, skiprows=6, sep=',')\n",
    "\n",
    "# Modify column names \n",
    "single_acc_df = single_acc_df.rename(columns={'count patches with [pcolor = yellow]': 'num_unfert_ovules',\\\n",
    "     'count patches with [pcolor = blue] / 6': 'num_col_ovules', 'count patches with [pcolor = red] / 6': 'num_ler_ovules',\\\n",
    "     'r3L': 'hr3_ler_tube_lengths', 'r6L': 'hr6_ler_tube_lengths', 'r9L': 'hr9_ler_tube_lengths', 'r24L': 'hr24_ler_tube_lengths',\\\n",
    "     'LHS-paramcombo-counter': 'param_num', 'r3C': 'hr3_col_tube_lengths', 'r6C': 'hr6_col_tube_lengths', 'r9C': 'hr9_col_tube_lengths',\\\n",
    "        'r24C': 'hr24_col_tube_lengths'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the model generated data for the double accession\n",
    "cols = ['accession', 'count patches with [pcolor = yellow]','count patches with [pcolor = blue] / 6', 'count patches with [pcolor = red] / 6', \\\n",
    "     'r3L', 'r6L', 'r9L', 'r24L','LHS-paramcombo-counter', 'r3C', 'r6C', 'r9C', 'r24C']\n",
    "double_acc_df = pd.read_csv(os.getcwd() + '\\\\Experiment Data\\\\calibration_data_double_accession', usecols=cols, skiprows=6, sep=',')\n",
    "\n",
    "# Modify column names \n",
    "double_acc_df = double_acc_df.rename(columns={'count patches with [pcolor = yellow]': 'num_unfert_ovules',\\\n",
    "     'count patches with [pcolor = blue] / 6': 'num_col_ovules', 'count patches with [pcolor = red] / 6': 'num_ler_ovules',\\\n",
    "     'r3L': 'hr3_ler_tube_lengths', 'r6L': 'hr6_ler_tube_lengths', 'r9L': 'hr9_ler_tube_lengths', 'r24L': 'hr24_ler_tube_lengths',\\\n",
    "     'LHS-paramcombo-counter': 'param_num', 'r3C': 'hr3_col_tube_lengths', 'r6C': 'hr6_col_tube_lengths', 'r9C': 'hr9_col_tube_lengths',\\\n",
    "        'r24C': 'hr24_col_tube_lengths'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e732f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the mean pollen tube lengths as stated in the Kolba-Capaldi paper in a dictionary. All pollen tube means are \n",
    "# based on single accession data and are measured at 3, 6, 9, and 24 hours post-germination. \n",
    "known_tube_means = {}\n",
    "known_tube_means['ler-only3'] = 0.066; known_tube_means['ler-only6'] = 0.094; known_tube_means['ler-only9'] = 0.251; known_tube_means['ler-only24'] = 0.324\n",
    "known_tube_means['col-only3'] = 0.093; known_tube_means['col-only6'] = 0.144; known_tube_means['col-only9'] = 0.342; known_tube_means['col-only24'] = 0.375\n",
    "\n",
    "# Create a list of exponential CDFs with shape parameters as estimated by Kolba-Capaldi paper. \n",
    "KC_ler_cdfs = []\n",
    "KC_col_cdfs = []\n",
    "\n",
    "for time in [3, 6, 9, 24]:\n",
    "    KC_ler_cdfs.append(stats.expon(loc = 0, scale = known_tube_means['ler-only'+str(time)]).cdf)\n",
    "    KC_col_cdfs.append(stats.expon(loc = 0, scale = known_tube_means['col-only'+str(time)]).cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tube_clean(tubes):\n",
    "    \n",
    "    # Inputs\n",
    "    # tubes - string object of space separated pollen tube lengths. \n",
    "    \n",
    "    # Outputs:\n",
    "    # tubes - numpy array of the input without zeros. \n",
    "\n",
    "    tubes = tubes.replace(\" \",\",\")\n",
    "    tubes = np.array(ast.literal_eval(tubes))\n",
    "    \n",
    "    if tubes.any() != 0:\n",
    "        new_tubes = tubes[np.nonzero(tubes)]\n",
    "    else:\n",
    "        new_tubes = np.array([0])\n",
    "    \n",
    "    return new_tubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_score(accession, col3, ler3, col6, ler6, col9, ler9, col24, ler24, known_tube_means, KC_ler_cdfs, KC_col_cdfs):\n",
    "    \n",
    "    # Inputs: \n",
    "    # colx / lerx - object with pollen tube lengths for col/ler at time x for one parameter realization. \n",
    "    \n",
    "    # Outputs:\n",
    "    # 1. sum (across all time values) of absolute difference between model mean pollen tube length and the \n",
    "    #    predicted value according to Kolba-Capaldi paper. \n",
    "    # 2. count (across all time values) where the KS test fails to reject the null hypothesis that the distribution of \n",
    "    #    pollen tube lengths from the model is the same as the Kolba-Capaldi paper.\n",
    "    \n",
    "    # Calculate the output described in step 1 (the first if statement detects which accession data to use, then \n",
    "    # we clean up the NetLogo ouput and perform this calculation in step 1, but if there are less than 20\n",
    "    # pollen tubes with nonzero length we just return a large quantity.)\n",
    "    if accession == 'ler-only':\n",
    "        clean3, clean6, clean9, clean24 = tube_clean(ler3), tube_clean(ler6), tube_clean(ler9), tube_clean(ler24)\n",
    "    else:\n",
    "        clean3, clean6, clean9, clean24 = tube_clean(col3), tube_clean(col6), tube_clean(col9), tube_clean(col24)\n",
    "    \n",
    "    if min(len(clean3), len(clean6), len(clean9), len(clean24)) < 20:\n",
    "        abs_diff_mean = 999999\n",
    "    else:\n",
    "        abs_diff_mean = abs(np.mean(clean3) - known_tube_means[accession + '3']) + \\\n",
    "        abs(np.mean(clean6) - known_tube_means[accession + '6']) + \\\n",
    "        abs(np.mean(clean9) - known_tube_means[accession + '9']) + \\\n",
    "        abs(np.mean(clean24) - known_tube_means[accession + '24'])\n",
    "    \n",
    "    if accession == 'ler-only':\n",
    "        if len(clean3) > 19:\n",
    "            pval3 = stats.kstest(clean3, KC_ler_cdfs[0])[1]\n",
    "        else:\n",
    "            pval3 = 0\n",
    "            \n",
    "        if len(clean6) > 19:\n",
    "            pval6 = stats.kstest(clean6, KC_ler_cdfs[1])[1]\n",
    "        else:\n",
    "            pval6 = 0\n",
    "            \n",
    "        if len(clean9) > 19:\n",
    "            pval9 = stats.kstest(clean9, KC_ler_cdfs[2])[1]\n",
    "        else:\n",
    "            pval9 = 0\n",
    "            \n",
    "        if len(clean24) > 19:\n",
    "            pval24 = stats.kstest(clean24, KC_ler_cdfs[3])[1]\n",
    "        else:\n",
    "            pval24 = 0\n",
    "    else:\n",
    "        if len(clean3) > 19:\n",
    "            pval3 = stats.kstest(clean3, KC_col_cdfs[0])[1]\n",
    "        else:\n",
    "            pval3 = 0\n",
    "            \n",
    "        if len(clean6) > 19:\n",
    "            pval6 = stats.kstest(clean6, KC_col_cdfs[1])[1]\n",
    "        else:\n",
    "            pval6 = 0\n",
    "            \n",
    "        if len(clean9) > 19:\n",
    "            pval9 = stats.kstest(clean9, KC_col_cdfs[2])[1]\n",
    "        else:\n",
    "            pval9 = 0\n",
    "            \n",
    "        if len(clean24) > 19:\n",
    "            pval24 = stats.kstest(clean24, KC_col_cdfs[3])[1]\n",
    "        else:\n",
    "            pval24 = 0\n",
    "    \n",
    "    KS_count = 1*(pval3 > 0.05) + 1*(pval6 > 0.05) + 1*(pval9 > 0.05) + 1*(pval24 > 0.05)\n",
    "    \n",
    "    return abs_diff_mean, KS_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f26dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each realization of the single accession model determine a mean score and distribution (KS) score. \n",
    "for k in range(len(single_acc_df)):\n",
    "    \n",
    "    if k % 10000 == 0:\n",
    "        print(100*k/len(single_acc_df))\n",
    "    sim = single_acc_df.iloc[k]\n",
    "    \n",
    "    val1, val2 = sim_score(sim.accession,\n",
    "                  sim.hr3_col_tube_lengths, sim.hr3_ler_tube_lengths,\n",
    "                  sim.hr6_col_tube_lengths, sim.hr6_ler_tube_lengths,\n",
    "                  sim.hr9_col_tube_lengths, sim.hr9_ler_tube_lengths,\n",
    "                  sim.hr24_col_tube_lengths, sim.hr24_ler_tube_lengths,\n",
    "                  known_tube_means, KC_ler_cdfs, KC_col_cdfs)\n",
    "    single_acc_df.at[k,'mean_score'] = val1\n",
    "    single_acc_df.at[k, 'ks_score'] =  val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each realization of the double accession model determine a fertilized ovule score. \n",
    "double_acc_df['fert_ovule_score'] = abs((60 - double_acc_df['num_unfert_ovules'])/60 - 0.93012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df987bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame that holds the results grouped and summed by parameter number for the single accession scores\n",
    "single_acc_scores_df = single_acc_df[['param_num', 'mean_score', 'ks_score']].groupby('param_num').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame that holds the results grouped and summed by parameter number for the double accession scores\n",
    "double_acc_scores_df = double_acc_df[['param_num', 'fert_ovule_score']].groupby('param_num').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce19765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the ranks.\n",
    "MLFO_ranks = single_acc_scores_df['mean_score'].rank(ascending=True, method='max') + double_acc_scores_df['fert_ovule_score'].rank(ascending=True, method='max')\n",
    "DFO_ranks = single_acc_scores_df['ks_score'].rank(ascending=False, method='max') + double_acc_scores_df['fert_ovule_score'].rank(ascending=True, method='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFO_ranks.sort_values(ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFO_ranks.sort_values(ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the rankings and modified dfs. \n",
    "pickle.dump(MLFO_ranks, open(\"MLFO_ranks.pickle\",\"wb\"))\n",
    "pickle.dump(DFO_ranks, open(\"DFO_ranks.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the LHS, print off the best parameters. \n",
    "LHS_df = pd.read_csv(os.getcwd() + '\\\\Experiment Data\\\\LHS.csv', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LHS_df.loc[MLFO_ranks.sort_values(ascending=True).head(100).index.tolist()].to_csv('best_mean_params.csv', index=False, header=None)\n",
    "LHS_df.loc[DFO_ranks.sort_values(ascending=True).head(100).index.tolist()].to_csv('best_distr_params.csv', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
